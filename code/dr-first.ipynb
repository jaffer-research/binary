{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['Mild', 'Moderate', 'No_DR', 'Proliferate_DR', 'Severe']\n",
      "Total images: 965, Training: 772, Validation: 193\n"
     ]
    }
   ],
   "source": [
    "# Define the transformation (in this case, just convert to tensor)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Path to your dataset folder (with subfolders for each class)\n",
    "data_dir = '/Users/jeff/code/dataset/dr/dr-2019-3662/filtered'\n",
    "\n",
    "# Load the dataset with ImageFolder\n",
    "full_dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "# Check the classes (order is determined by alphabetical order of folder names)\n",
    "print(\"Classes:\", full_dataset.classes)\n",
    "\n",
    "# Calculate the sizes for the training and validation sets (80:20 split)\n",
    "dataset_size = len(full_dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dl = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "valid_dl = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"Total images: {dataset_size}, Training: {train_size}, Validation: {val_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building The CNN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Four Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential()\n",
    "\n",
    "model.add_module('conv1', nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1))\n",
    "model.add_module('relu1', nn.ReLU())        \n",
    "model.add_module('pool1', nn.MaxPool2d(kernel_size=2))  \n",
    "model.add_module('dropout1', nn.Dropout(p=0.5)) \n",
    "\n",
    "model.add_module('conv2', nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1))\n",
    "model.add_module('relu2', nn.ReLU())        \n",
    "model.add_module('pool2', nn.MaxPool2d(kernel_size=2))   \n",
    "model.add_module('dropout2', nn.Dropout(p=0.5)) \n",
    "\n",
    "model.add_module('conv3', nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1))\n",
    "model.add_module('relu3', nn.ReLU())        \n",
    "model.add_module('pool3', nn.MaxPool2d(kernel_size=2))   \n",
    "\n",
    "model.add_module('conv4', nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1))\n",
    "model.add_module('relu4', nn.ReLU())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pooling and Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_module('pool4', nn.AvgPool2d(kernel_size=8)) \n",
    "model.add_module('flatten', nn.Flatten()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fully Connected (FC) and Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_module('fc1', nn.Linear(2304, 256))\n",
    "model.add_module('relu_fc1', nn.ReLU())\n",
    "model.add_module('fc2', nn.Linear(256, 5))\n",
    "model.add_module('softmax', nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu1): ReLU()\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu2): ReLU()\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu3): ReLU()\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu4): ReLU()\n",
       "  (pool4): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=2304, out_features=256, bias=True)\n",
       "  (relu_fc1): ReLU()\n",
       "  (fc2): Linear(in_features=256, out_features=5, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the model to MPS device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps:0\")\n",
    "# device = torch.device(\"cpu\")\n",
    "model = model.to(device) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model With Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train accuracy: 0.1904, Val accuracy: 0.2176\n",
      "Epoch 2 - Train accuracy: 0.2021, Val accuracy: 0.2176\n",
      "Epoch 3 - Train accuracy: 0.3070, Val accuracy: 0.3472\n",
      "Epoch 4 - Train accuracy: 0.3782, Val accuracy: 0.3472\n",
      "Epoch 5 - Train accuracy: 0.4184, Val accuracy: 0.3990\n",
      "Early stopping at epoch 5 as training accuracy did not reach 80%.\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()  # for multi-class\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train(model, num_epochs, train_dl, valid_dl):\n",
    "    loss_hist_train = [0] * num_epochs\n",
    "    accuracy_hist_train = [0] * num_epochs\n",
    "    loss_hist_valid = [0] * num_epochs\n",
    "    accuracy_hist_valid = [0] * num_epochs\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        for x_batch, y_batch in train_dl:\n",
    "            x_batch = x_batch.to(device) \n",
    "            y_batch = y_batch.to(device)  # y_batch should be integer labels in {0,1,2,3,4}\n",
    "\n",
    "            outputs = model(x_batch)  # Forward pass (output shape: (batch, 5))\n",
    "            loss = loss_fn(outputs, y_batch)  # Compute loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            running_loss += loss.item() * y_batch.size(0)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            running_corrects += (preds == y_batch).float().sum().cpu().item()\n",
    "\n",
    "        loss_hist_train[epoch] = running_loss / len(train_dl.dataset)\n",
    "        accuracy_hist_train[epoch] = running_corrects / len(train_dl.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        running_loss_val = 0.0\n",
    "        running_corrects_val = 0\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in valid_dl:\n",
    "                x_batch = x_batch.to(device) \n",
    "                y_batch = y_batch.to(device)\n",
    "                outputs = model(x_batch)\n",
    "                loss = loss_fn(outputs, y_batch)\n",
    "                running_loss_val += loss.item() * y_batch.size(0)\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                running_corrects_val += (preds == y_batch).float().sum().cpu().item()\n",
    "\n",
    "        loss_hist_valid[epoch] = running_loss_val / len(valid_dl.dataset)\n",
    "        accuracy_hist_valid[epoch] = running_corrects_val / len(valid_dl.dataset)\n",
    "        \n",
    "        print(f'Epoch {epoch+1} - Train accuracy: {accuracy_hist_train[epoch]:.4f}, Val accuracy: {accuracy_hist_valid[epoch]:.4f}')\n",
    "\n",
    "        # Early stopping: if after 5 epochs training accuracy is still below 80%, stop training.\n",
    "        if epoch >= 4 and accuracy_hist_train[epoch] < 0.8:\n",
    "            print(f\"Early stopping at epoch {epoch+1} as training accuracy did not reach 80%.\")\n",
    "            break\n",
    "\n",
    "    return loss_hist_train, loss_hist_valid, accuracy_hist_train, accuracy_hist_valid\n",
    "\n",
    "torch.manual_seed(1)\n",
    "num_epochs = 20\n",
    "hist = train(model, num_epochs, train_dl, valid_dl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn-py3.13",
   "language": "python",
   "name": "cnn-py3.13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
