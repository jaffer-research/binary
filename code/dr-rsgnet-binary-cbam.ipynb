{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset as is with a WeightedRandomSampler to oversample classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['no_dr', 'with_dr']\n",
      "Training set class counts: [20635 22341]\n",
      "Total images: 53720, Training: 42976, Validation: 10744\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler, random_split\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "# Define the transformation: resize to 224x224, convert to tensor, and normalize\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Path to your dataset folder (containing subfolders 'no_dr' and 'with_dr')\n",
    "data_dir = '/Users/jeff/code/dataset/dr/binary_data'\n",
    "\n",
    "# Load the dataset with ImageFolder\n",
    "full_dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "print(\"Classes:\", full_dataset.classes)  # Expected output: ['no_dr', 'with_dr']\n",
    "\n",
    "# Calculate the sizes for the training and validation sets (80:20 split)\n",
    "dataset_size = len(full_dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "# Split the dataset into training and validation subsets\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# --- Oversampling code for the training set ---\n",
    "# Extract the labels for each sample in the training subset\n",
    "train_labels = [full_dataset.targets[i] for i in train_dataset.indices]\n",
    "\n",
    "# Compute the count for each class in the training set\n",
    "class_counts = np.bincount(train_labels)\n",
    "print(\"Training set class counts:\", class_counts)\n",
    "\n",
    "# Calculate weights for each class (inverse frequency)\n",
    "weights_per_class = 1.0 / class_counts\n",
    "\n",
    "# Assign a weight to each sample in the training subset based on its class label\n",
    "samples_weights = [weights_per_class[label] for label in train_labels]\n",
    "samples_weights = torch.DoubleTensor(samples_weights)\n",
    "\n",
    "# Create the WeightedRandomSampler for the training DataLoader\n",
    "sampler = WeightedRandomSampler(weights=samples_weights, num_samples=len(samples_weights), replacement=True)\n",
    "\n",
    "# Create DataLoaders using the sampler for the training set and standard shuffling for validation set\n",
    "train_dl = DataLoader(train_dataset, batch_size=32, sampler=sampler, num_workers=4)\n",
    "valid_dl = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"Total images: {dataset_size}, Training: {train_size}, Validation: {val_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building The RSG_Net CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- CBAM Implementation ---\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, reduction=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, in_planes // reduction, kernel_size=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_planes // reduction, in_planes, kernel_size=1, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        padding = kernel_size // 2\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Along channel axis: compute average and max\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x_cat = torch.cat([avg_out, max_out], dim=1)\n",
    "        x_out = self.conv(x_cat)\n",
    "        return self.sigmoid(x_out)\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_planes, reduction=16, kernel_size=7):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_att = ChannelAttention(in_planes, reduction)\n",
    "        self.spatial_att = SpatialAttention(kernel_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply channel attention\n",
    "        out = x * self.channel_att(x)\n",
    "        # Apply spatial attention\n",
    "        out = out * self.spatial_att(out)\n",
    "        return out\n",
    "\n",
    "# --- Updated CNN Architecture with CBAM ---\n",
    "\n",
    "class RSGNet224_CBAM(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(RSGNet224_CBAM, self).__init__()\n",
    "        \n",
    "        # --- Block 1 ---\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.cbam1 = CBAM(in_planes=32)  # CBAM for Block 1\n",
    "        \n",
    "        # --- Block 2 ---\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.cbam2 = CBAM(in_planes=128)  # CBAM for Block 2\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        # After two poolings: 224 -> 112 -> 56; feature map size: 128 x 56 x 56\n",
    "        self.fc1 = nn.Linear(128 * 56 * 56, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.dropout_fc = nn.Dropout(p=0.1)\n",
    "        self.fc2 = nn.Linear(128, num_classes)  # Output 2 logits for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Block 1\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.cbam1(x)  # Apply CBAM after Block 1\n",
    "\n",
    "        # Block 2\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.cbam2(x)  # Apply CBAM after Block 2\n",
    "\n",
    "        # Flatten and fully connected layers\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout_fc(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning to the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example using the class-based approach from the RSGNet224 snippet:\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "model = RSGNet224_CBAM(num_classes=2)  # Instantiate your model class\n",
    "model = model.to(device)          # Move model parameters to the selected device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model With Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train accuracy: 0.7410, Val accuracy: 0.7623\n",
      "Epoch 2 - Train accuracy: 0.7829, Val accuracy: 0.8204\n",
      "Epoch 3 - Train accuracy: 0.7928, Val accuracy: 0.8139\n",
      "Epoch 4 - Train accuracy: 0.7959, Val accuracy: 0.7843\n",
      "Epoch 5 - Train accuracy: 0.8019, Val accuracy: 0.7866\n",
      "Epoch 6 - Train accuracy: 0.8000, Val accuracy: 0.8230\n",
      "Epoch 7 - Train accuracy: 0.8018, Val accuracy: 0.8191\n",
      "Epoch 8 - Train accuracy: 0.8172, Val accuracy: 0.8161\n",
      "Epoch 9 - Train accuracy: 0.8420, Val accuracy: 0.8199\n",
      "Epoch 10 - Train accuracy: 0.8746, Val accuracy: 0.7934\n",
      "Epoch 11 - Train accuracy: 0.9012, Val accuracy: 0.8139\n",
      "Epoch 12 - Train accuracy: 0.9227, Val accuracy: 0.8219\n",
      "Epoch 13 - Train accuracy: 0.9382, Val accuracy: 0.8237\n",
      "Epoch 14 - Train accuracy: 0.9513, Val accuracy: 0.8146\n",
      "Epoch 15 - Train accuracy: 0.9576, Val accuracy: 0.8191\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     58\u001b[39m torch.manual_seed(\u001b[32m1\u001b[39m)\n\u001b[32m     59\u001b[39m num_epochs = \u001b[32m20\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m hist = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dl\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, num_epochs, train_dl, valid_dl)\u001b[39m\n\u001b[32m     25\u001b[39m optimizer.step()\n\u001b[32m     26\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m running_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m * y_batch.size(\u001b[32m0\u001b[39m)\n\u001b[32m     29\u001b[39m preds = torch.argmax(outputs, dim=\u001b[32m1\u001b[39m)\n\u001b[32m     30\u001b[39m running_corrects += (preds == y_batch).float().sum().cpu().item()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# For binary classification, define class weights (example values; adjust as needed)\n",
    "weights = torch.tensor([1.0, 2.0], dtype=torch.float)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=weights.to(device))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train(model, num_epochs, train_dl, valid_dl):\n",
    "    loss_hist_train = [0] * num_epochs\n",
    "    accuracy_hist_train = [0] * num_epochs\n",
    "    loss_hist_valid = [0] * num_epochs\n",
    "    accuracy_hist_valid = [0] * num_epochs\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for x_batch, y_batch in train_dl:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            outputs = model(x_batch)\n",
    "            loss = loss_fn(outputs, y_batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            running_loss += loss.item() * y_batch.size(0)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            running_corrects += (preds == y_batch).float().sum().cpu().item()\n",
    "\n",
    "        loss_hist_train[epoch] = running_loss / len(train_dl.dataset)\n",
    "        accuracy_hist_train[epoch] = running_corrects / len(train_dl.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        running_loss_val = 0.0\n",
    "        running_corrects_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in valid_dl:\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                \n",
    "                outputs = model(x_batch)\n",
    "                loss = loss_fn(outputs, y_batch)\n",
    "                \n",
    "                running_loss_val += loss.item() * y_batch.size(0)\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                running_corrects_val += (preds == y_batch).float().sum().cpu().item()\n",
    "\n",
    "        loss_hist_valid[epoch] = running_loss_val / len(valid_dl.dataset)\n",
    "        accuracy_hist_valid[epoch] = running_corrects_val / len(valid_dl.dataset)\n",
    "        \n",
    "        print(f'Epoch {epoch+1} - Train accuracy: {accuracy_hist_train[epoch]:.4f}, Val accuracy: {accuracy_hist_valid[epoch]:.4f}')\n",
    "\n",
    "    return loss_hist_train, loss_hist_valid, accuracy_hist_train, accuracy_hist_valid\n",
    "\n",
    "torch.manual_seed(1)\n",
    "num_epochs = 20\n",
    "hist = train(model, num_epochs, train_dl, valid_dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x_arr = np.arange(len(hist[0])) + 1\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(x_arr, hist[0], '-o', label='Train loss')\n",
    "ax.plot(x_arr, hist[1], '--<', label='Validation loss')\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_xlabel('Epoch', size=15)\n",
    "ax.set_ylabel('Loss', size=15)\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(x_arr, hist[2], '-o', label='Train acc.')\n",
    "ax.plot(x_arr, hist[3], '--<', label='Validation acc.')\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_xlabel('Epoch', size=15)\n",
    "ax.set_ylabel('Accuracy', size=15)\n",
    "\n",
    "#plt.savefig('figures/14_17.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-class metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in dataloader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            outputs = model(x_batch)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(y_batch.numpy())\n",
    "    return np.array(all_labels), np.array(all_preds)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "y_true, y_pred = evaluate_model(model, valid_dl, device)\n",
    "\n",
    "# Print per-class metrics (precision, recall, F1-score)\n",
    "print(classification_report(y_true, y_pred, target_names=[str(i) for i in range(2)]))\n",
    "\n",
    "# Optionally, compute the confusion matrix to calculate sensitivity and specificity manually\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Compute per-class sensitivity (Recall) and specificity\n",
    "num_classes = cm.shape[0]\n",
    "sensitivity = {}\n",
    "specificity = {}\n",
    "for i in range(num_classes):\n",
    "    TP = cm[i, i]\n",
    "    FN = cm[i, :].sum() - TP\n",
    "    FP = cm[:, i].sum() - TP\n",
    "    TN = cm.sum() - (TP + FN + FP)\n",
    "    \n",
    "    sensitivity[i] = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    specificity[i] = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "\n",
    "print(\"Per-class Sensitivity (Recall):\", sensitivity)\n",
    "print(\"Per-class Specificity:\", specificity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    # Annotate each cell with the numeric value\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                     horizontalalignment='center',\n",
    "                     color='white' if cm[i, j] > thresh else 'black')\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assume 'cm' is your confusion matrix and you have 5 classes (0-4)\n",
    "class_names = [str(i) for i in range(2)]\n",
    "plot_confusion_matrix(cm, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn-py3.13",
   "language": "python",
   "name": "cnn-py3.13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
